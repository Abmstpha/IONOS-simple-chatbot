# IONOS Chatbot

A full‑stack chatbot powered by LangGraph/LangChain and IONOS models. It supports web search, optional RAG over URLs, and an extensible tool system.

## What’s inside
- Backend: FastAPI service with a LangGraph ReAct agent (`backend/`).
- Frontends: Next.js starter and Streamlit app (`frontends/`).
- Docs: MDX documentation site (`docs/`).

## Features
- Chat with IONOS‑hosted models via a simple HTTP API.
- Tools: web search (Tavily) and optional local document search (TF‑IDF retriever).
- Optional RAG: initialize from a URL and retrieve top‑K chunks (if enabled).
- Easy to add your own tools.

## Requirements
- Python 3.10+
- Node.js 18+
- IONOS_API_KEY (required)
- TAVILY_API_KEY (optional, for web search)

## Quickstart
1) Backend: follow the Windows‑friendly steps in [Backend Setup](/docs/backend/setup).
2) Choose a frontend:
	- [Next.js Setup](/docs/frontend/nextjs/setup)
	- [Streamlit Overview](/docs/frontend/streamlit)
3) Send a chat request with header `x-model-id` (e.g., `meta-llama/Llama-3.3-70B-Instruct`).

## How it works
The client sends messages to FastAPI → the agent reasons (ReAct) → tools are called as needed (e.g., `web_search`, `search_documents`) → the model produces a final answer.

Learn more:
- [Backend API](/docs/backend/api)
- [Agent Tools](/docs/backend/agent-tools)
- [Troubleshooting](/docs/backend/troubleshooting)
